# Comprehensive Testing Pipeline for Fumadocs Migration
# Runs all test suites with performance monitoring and quality gates

name: Comprehensive Testing Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run nightly regression tests
    - cron: '0 2 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  NODE_VERSION: '18'
  FORCE_COLOR: 1
  CI: true

jobs:
  # ================================
  # Quality Gates and Pre-checks
  # ================================
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: TypeScript type checking
        run: yarn typecheck
        
      - name: ESLint code quality
        run: yarn lint --max-warnings 0
        
      - name: Prettier formatting check
        run: yarn format:check
        
      - name: Security audit
        run: yarn audit --level moderate
        
      - name: Dependency vulnerability scan
        run: npx audit-ci --config audit-ci.json

  # ================================
  # Unit and Component Testing
  # ================================
  unit-component-tests:
    name: Unit & Component Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: quality-gates
    
    strategy:
      matrix:
        test-group: [components, utils, scripts, validation]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Run tests with coverage
        run: |
          yarn test \
            --coverage \
            --reporter=verbose \
            --reporter=junit \
            --outputFile=junit-${{ matrix.test-group }}.xml \
            tests/${{ matrix.test-group }}
            
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: ${{ matrix.test-group }}
          name: ${{ matrix.test-group }}-coverage
          
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.test-group }}
          path: |
            junit-${{ matrix.test-group }}.xml
            coverage/

  # ================================
  # Build Process Testing
  # ================================
  build-tests:
    name: Build Process Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: quality-gates
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Install SDK dependencies
        run: yarn install-sdk-dependencies
        
      - name: Test build pipeline scripts
        run: yarn test tests/build
        
      - name: Test content generation
        run: |
          yarn fumadocs:build-glossary
          yarn fumadocs:generate-precompiles
          yarn fumadocs:content-pipeline
          
      - name: Test full build process
        run: yarn build
        
      - name: Validate build output
        run: |
          test -d .next
          test -f .next/static/chunks/main-*.js
          test -f public/api/glossary.json
          
      - name: Test build performance
        run: yarn test tests/build/build-processes.test.ts
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-output
          path: |
            .next/
            public/api/
          retention-days: 7

  # ================================
  # Content Validation
  # ================================
  content-validation:
    name: Content Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: quality-gates
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Validate MDX content structure
        run: yarn test tests/validation/content-validation.test.ts
        
      - name: Check internal links
        run: |
          yarn fumadocs:content-pipeline --validate-links
          
      - name: Validate navigation structure
        run: |
          yarn fumadocs:content-pipeline --validate-navigation
          
      - name: Check content accessibility
        run: |
          yarn fumadocs:content-pipeline --validate-accessibility
          
      - name: Generate validation report
        run: |
          yarn fumadocs:content-pipeline --generate-report > content-validation-report.md
          
      - name: Upload validation report
        uses: actions/upload-artifact@v3
        with:
          name: content-validation-report
          path: content-validation-report.md

  # ================================
  # End-to-End Testing
  # ================================
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [build-tests]
    
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
        viewport: [desktop, tablet, mobile]
        exclude:
          # Reduce matrix size for faster execution
          - browser: firefox
            viewport: tablet
          - browser: webkit
            viewport: tablet
            
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: build-output
          
      - name: Install Playwright browsers
        run: npx playwright install ${{ matrix.browser }}
        
      - name: Start development server
        run: |
          yarn start &
          npx wait-on http://localhost:3000 --timeout 60000
          
      - name: Run E2E tests
        run: |
          yarn test:e2e \
            --project=${{ matrix.browser }} \
            --grep="@${{ matrix.viewport }}" \
            --reporter=junit \
            --output-dir=e2e-results/${{ matrix.browser }}-${{ matrix.viewport }}
        env:
          VIEWPORT: ${{ matrix.viewport }}
          
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-results-${{ matrix.browser }}-${{ matrix.viewport }}
          path: |
            e2e-results/
            test-results/
            
      - name: Upload failure screenshots
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: e2e-screenshots-${{ matrix.browser }}-${{ matrix.viewport }}
          path: test-results/

  # ================================
  # Performance Testing
  # ================================
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [build-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: build-output
          
      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.12.x
        
      - name: Start production server
        run: |
          yarn build
          yarn start &
          npx wait-on http://localhost:3000 --timeout 60000
          
      - name: Run Lighthouse CI
        run: lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
          
      - name: Run performance benchmarks
        run: yarn test tests/performance/benchmarks.test.ts
        
      - name: Analyze bundle size
        run: |
          npx bundlesize
          npx webpack-bundle-analyzer .next/static/chunks/*.js --no-open --report bundle-analysis.html
          
      - name: Check Core Web Vitals
        run: |
          yarn test:e2e --grep="Core Web Vitals" --reporter=json > cwv-results.json
          
      - name: Upload performance reports
        uses: actions/upload-artifact@v3
        with:
          name: performance-reports
          path: |
            .lighthouseci/
            bundle-analysis.html
            cwv-results.json

  # ================================
  # Security Testing
  # ================================
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: quality-gates
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Run CodeQL Analysis
        uses: github/codeql-action/analyze@v2
        with:
          languages: javascript,typescript
          
      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=medium
          
      - name: OWASP Dependency Check
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: 'arbitrum-docs'
          path: '.'
          format: 'HTML'
          
      - name: Upload security reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: reports/

  # ================================
  # Accessibility Testing
  # ================================
  accessibility-tests:
    name: Accessibility Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [build-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: build-output
          
      - name: Start server
        run: |
          yarn start &
          npx wait-on http://localhost:3000 --timeout 60000
          
      - name: Run axe accessibility tests
        run: |
          npx @axe-core/cli http://localhost:3000 \
            --include "#main-content" \
            --tags wcag2a,wcag2aa,wcag21aa \
            --reporter junit \
            --output-dir a11y-results
            
      - name: Run Pa11y accessibility tests
        run: |
          npx pa11y-ci \
            --sitemap http://localhost:3000/sitemap.xml \
            --reporter junit \
            > pa11y-results.xml
            
      - name: Upload accessibility reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: accessibility-reports
          path: |
            a11y-results/
            pa11y-results.xml

  # ================================
  # Regression Testing
  # ================================
  regression-tests:
    name: Regression Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: [e2e-tests, performance-tests]
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[regression]')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Need full history for regression comparison
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Install dependencies
        run: yarn install --frozen-lockfile
        
      - name: Download performance baseline
        uses: actions/download-artifact@v3
        with:
          name: performance-baseline
        continue-on-error: true
        
      - name: Run regression test suite
        run: |
          yarn test tests/e2e/user-flows.test.ts \
            --grep="regression" \
            --reporter=json > regression-results.json
            
      - name: Compare performance metrics
        run: |
          yarn test tests/performance/benchmarks.test.ts \
            --grep="regression" \
            --reporter=json > performance-regression.json
            
      - name: Generate regression report
        run: |
          node scripts/generate-regression-report.js \
            regression-results.json \
            performance-regression.json \
            > regression-report.md
            
      - name: Upload regression report
        uses: actions/upload-artifact@v3
        with:
          name: regression-report
          path: regression-report.md
          
      - name: Comment regression results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('regression-report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Regression Test Results\n\n${report}`
            });

  # ================================
  # Test Results Aggregation
  # ================================
  test-results:
    name: Aggregate Test Results
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [
      unit-component-tests,
      build-tests,
      content-validation,
      e2e-tests,
      performance-tests,
      accessibility-tests
    ]
    if: always()
    
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v3
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Install report generators
        run: |
          npm install -g junit-report-merger
          npm install -g mochawesome-merge mochawesome-report-generator
          
      - name: Merge test results
        run: |
          jrm combined-junit.xml test-results-*/*.xml
          
      - name: Generate test summary
        run: |
          echo "# Test Results Summary" > test-summary.md
          echo "" >> test-summary.md
          echo "## Unit & Component Tests" >> test-summary.md
          find . -name "junit-*.xml" -exec echo "- {}" \; >> test-summary.md
          echo "" >> test-summary.md
          echo "## E2E Tests" >> test-summary.md
          find . -name "e2e-results*" -type d -exec echo "- {}" \; >> test-summary.md
          echo "" >> test-summary.md
          echo "## Performance Tests" >> test-summary.md
          test -f performance-reports/cwv-results.json && echo "- Core Web Vitals: ‚úÖ" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Coverage" >> test-summary.md
          find . -name "coverage" -type d -exec echo "- {}" \; >> test-summary.md
          
      - name: Calculate overall test metrics
        run: |
          echo "Calculating test metrics..."
          
          # Count total tests
          TOTAL_TESTS=$(grep -r "testcase" . --include="*.xml" | wc -l || echo "0")
          FAILED_TESTS=$(grep -r "failure\|error" . --include="*.xml" | wc -l || echo "0")
          PASSED_TESTS=$((TOTAL_TESTS - FAILED_TESTS))
          
          echo "Total Tests: $TOTAL_TESTS"
          echo "Passed: $PASSED_TESTS"
          echo "Failed: $FAILED_TESTS"
          
          # Calculate success rate
          if [ $TOTAL_TESTS -gt 0 ]; then
            SUCCESS_RATE=$((PASSED_TESTS * 100 / TOTAL_TESTS))
            echo "Success Rate: $SUCCESS_RATE%"
          fi
          
          # Set job output
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "success_rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
          
      - name: Upload combined results
        uses: actions/upload-artifact@v3
        with:
          name: combined-test-results
          path: |
            combined-junit.xml
            test-summary.md
            
      - name: Publish test results
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: 'Test Results Summary'
          path: 'combined-junit.xml'
          reporter: 'java-junit'
          
      - name: Update status badge
        if: github.ref == 'refs/heads/main'
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            -H "Content-Type: application/json" \
            -d '{"state":"success","target_url":"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}","description":"All tests passing","context":"continuous-integration/tests"}' \
            "${{ github.api_url }}/repos/${{ github.repository }}/statuses/${{ github.sha }}"

  # ================================
  # Quality Gates Check
  # ================================
  quality-gates-final:
    name: Final Quality Gates
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [test-results]
    if: always()
    
    steps:
      - name: Download test results
        uses: actions/download-artifact@v3
        with:
          name: combined-test-results
          
      - name: Check quality gates
        run: |
          echo "Checking quality gates..."
          
          # Check test success rate (must be > 95%)
          SUCCESS_RATE=$(cat test-summary.md | grep "Success Rate:" | cut -d' ' -f3 | tr -d '%' || echo "0")
          if [ $SUCCESS_RATE -lt 95 ]; then
            echo "‚ùå Test success rate ($SUCCESS_RATE%) below threshold (95%)"
            exit 1
          fi
          
          # Check coverage (from codecov reports)
          # This would be enhanced with actual coverage data
          echo "‚úÖ All quality gates passed"
          
      - name: Set final status
        if: success()
        run: echo "üéâ All tests passed and quality gates met!"
        
      - name: Fail on quality gate violations
        if: failure()
        run: |
          echo "‚ùå Quality gates failed!"
          exit 1