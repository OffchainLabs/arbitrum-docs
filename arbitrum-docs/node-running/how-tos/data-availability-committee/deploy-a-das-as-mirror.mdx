---
title: 'How to configure a Data Availability Committee: deploy a Data Availability Server (DAS) as a mirror'
description: This how-to will help you deploy a Data Availability Server (DAS) as a mirror
author: jose-franco
sidebar_label: Deploy a mirror DAS
sidebar_position: 3
content-type: how-to
---

import PublicPreviewBannerPartial from '../../../partials/_public-preview-banner-partial.md';

<PublicPreviewBannerPartial />

<p>
  <a data-quicklook-from="arbitrum-anytrust-protocol">AnyTrust</a> chains rely on an external Data
  Availability Committee (DAC) to store data and provide it on demand instead of using the{' '}
  <a data-quicklook-from="parent-chain">parent chain</a> as the Data Availability (DA) layer. The
  members of the DAC run a Data Availability Server (DAS) to handle these operations.
</p>

In this how-to you'll learn how to deploy a DAS as a mirror and enable a REST interface to respond to requests of stored information. For more information related to configuring a DAC, please see the [Introduction](./introduction.mdx).

You should be familiarized with how the AnyTrust protocol works and what's the role of the DAC in the protocol. You can find more information about the AnyTrust protocol in [Inside AnyTrust](/inside-anytrust.mdx). It is also recommended to be familiarized with [Kubernetes](https://kubernetes.io/) as the examples on this guide are based on that software.

import HowDASWorkContent from './partials/_1-how-das-work-content.mdx';

## How does a Data Availability Server work?

<HowDASWorkContent />

import DASConfigurationOptionsInterfaces from './partials/_2.1-das-configuration-options-interfaces.mdx';
import DASConfigurationOptionsStorage from './partials/_2.2-das-configuration-options-storage.mdx';
import DASConfigurationOptionsCaching from './partials/_2.3-das-configuration-options-caching.mdx';
import DASConfigurationOptionsStateSync from './partials/_2.4-das-configuration-options-state-sync.mdx';

## Configuration options

When setting up a DAS, there are certain options you can configure to suit your infrastructure needs:

### Interfaces available in a DAS

<DASConfigurationOptionsInterfaces />

### Storage options

<DASConfigurationOptionsStorage />

### Caching

<DASConfigurationOptionsCaching />

### State synchronization

<DASConfigurationOptionsStateSync />

## How to deploy the DAS as a mirror

We now start the process of deploying the DAS as a mirror. Remember that you can reach out to us on Discord if you are having trouble following this process.

### Step 0: Prerequisites

In order to setup your DAS, you'll need the following information:

- The latest Nitro docker image: `@latestNitroNodeImage@`
- An RPC endpoint for the <a data-quicklook-from="parent-chain">parent chain</a>. It is recommended to use a [third-party provider RPC](/node-running/node-providers.mdx#third-party-rpc-providers) or [run your own node](/node-running/how-tos/running-an-orbit-node.mdx) to prevent being rate limited.
- The SequencerInbox contract address in the parent chain.
- URL of the list of REST endpoints of other DA servers to configure the REST aggregator.

In terms of hardware requirements, these are the minimum specs that your infrastructure should comply with to run a stable DAS:

- RAM:
- CPU:

Depending on the storage backend you use for your DAS, you'll need to configure the appropriate infrastructure: for example, an S3 bucket if you choose S3, or a local volume if you choose any of the local backend options. When using a local volume, it is recommended to use …

### Step 1: Set up a persistent volume

First, we'll set up a volume to store the DAS database. In k8s, we can use a configuration like this:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: das-mirror
spec:
  accessModes:
    - ReadWriteOnce
  resources:
  requests:
    storage: 200Gi
  storageClassName: gp2
```

### Step 2: Deploy the mirror DAS

To run the mirror DAS, we'll use the `daserver` tool and we'll configure the following parameters:

| Parameter                                                                   | Description                                                                                                                                                                                 |
| --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| --data-availability.parent-chain-node-url                                   | RPC endpoint of a parent chain node                                                                                                                                                         |
| --data-availability.sequencer-inbox-address                                 | Address of the SequencerInbox in the parent chain                                                                                                                                           |
| --enable-rest                                                               | Enables the REST server listening on --rest-addr and --rest-port                                                                                                                            |
| --rest-addr                                                                 | REST server listening interface (default "localhost")                                                                                                                                       |
| --rest-port                                                                 | (Optional) REST server listening port (default 9877)                                                                                                                                        |
| --log-level                                                                 | Log level: 1 - ERROR, 2 - WARN, 3 - INFO, 4 - DEBUG, 5 - TRACE (default 3)                                                                                                                  |
| --data-availability.rest-aggregator.enable                                  | Enables retrieval of sequencer batch data from a list of remote REST endpoints                                                                                                              |
| --data-availability.rest-aggregator.online-url-list                         | A URL to a list of URLs of REST DAS endpoints that is checked at startup. This option is additive with the urls option                                                                      |
| --data-availability.rest-aggregator.urls                                    | List of URLs including 'http://' or 'https://' prefixes and port numbers to REST DAS endpoints. This option is additive with the online-url-list option                                     |
| --data-availability.rest-aggregator.sync-to-storage.check-already-exists    | When using a REST aggregator, checks if the data already exists in this DAS's storage. Must be disabled for fast sync with an IPFS backend (default true)                                   |
| --data-availability.rest-aggregator.sync-to-storage.eager                   | When using a REST aggregator, eagerly syncs batch data to this DAS's storage from the rest endpoints, using the parent chain as the index of batch data hashes; otherwise only syncs lazily |
| --data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block | When using a REST aggregator that's eagerly syncing, starts indexing forward from this block from the parent chain. Only used if there is no sync state.                                    |
| --data-availability.rest-aggregator.sync-to-storage.retention-period        | When using a REST aggregator, period to retain the synced data (defaults to forever)                                                                                                        |
| --data-availability.rest-aggregator.sync-to-storage.state-dir               | When using a REST aggregator, directory to store the sync state in, i.e. the block number currently synced up to, so that it doesn't sync from scratch each time                            |

To enable caching, you can use the following parameters:

| Parameter                                  | Description                                                             |
| ------------------------------------------ | ----------------------------------------------------------------------- |
| --data-availability.local-cache.enable     | Enables local in-memory caching of sequencer batch data                 |
| --data-availability.local-cache.expiration | Expiration time for in-memory cached sequencer batches (default 1h0m0s) |

Finally, for the storage backends you wish to configure, use the following parameters (toggle between the different options to see all available parameters):

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import S3Parameters from './partials/parameters/_s3-parameters.mdx';
import LocalBadgerDBParameters from './partials/parameters/_local-badger-db-parameters.mdx';
import LocalFilesParameters from './partials/parameters/_local-files-parameters.mdx';
import IPFSParameters from './partials/parameters/_ipfs-parameters.mdx';

<div className="dynamic-content-tabs">
  <Tabs className="tabgroup" defaultValue={null}>
    <TabItem value="s3-bucket" label="AWS S3 bucket">
      <S3Parameters />
    </TabItem>
    <TabItem value="badger-db" label="Local Badger database">
      <LocalBadgerDBParameters />
    </TabItem>
    <TabItem value="local-files" label="Local files">
      <LocalFilesParameters />
    </TabItem>
    <TabItem value="ipfs" label="IPFS">
      <IPFSParameters />
    </TabItem>
  </Tabs>
</div>

Here's an example `daserver` command for a committee member DAS that:

- Enables local cache
- Enables AWS S3 bucket storage that doesn't discard data after expiring ([archive](#archive-da-servers-for-mirror-das))
- Enables local Badger database storage that doesn't discard data after expiring ([archive](#archive-da-servers-for-mirror-das))
- Uses a local committee member DAS as part of the REST aggregator

```bash
daserver
    --data-availability.parent-chain-node-url "<YOUR PARENT CHAIN RPC ENDPOINT>"
    --data-availability.sequencer-inbox-address "<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>"
    --enable-rest
    --rest-addr '0.0.0.0'
    --log-level 3
    --data-availability.local-cache.enable
    --data-availability.rest-aggregator.enable
    --data-availability.rest-aggregator.urls "http://your-committee-member.svc.cluster.local:9877"
    --data-availability.rest-aggregator.online-url-list "<URL TO LIST OF REST ENDPOINTS>"
    --data-availability.rest-aggregator.sync-to-storage.eager
    --data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block "BLOCK NUMBER"
    --data-availability.rest-aggregator.sync-to-storage.state-dir /home/user/data/syncState
    --data-availability.s3-storage.enable
    --data-availability.s3-storage.access-key "<YOUR ACCESS KEY>"
    --data-availability.s3-storage.bucket "<YOUR BUCKET>"
    --data-availability.s3-storage.region "<YOUR REGION>"
    --data-availability.s3-storage.secret-key "<YOUR SECRET KEY>"
    --data-availability.s3-storage.object-prefix "<YOUR OBJECT KEY PREFIX>/"
    --data-availability.s3-storage.discard-after-timeout false
    --data-availability.local-db-storage.enable
    --data-availability.local-db-storage.data-dir /home/user/data/badgerdb
    --data-availability.local-db-storage.discard-after-timeout false
```

And here's an example of how to use a k8s deployment to run the that command:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
    name: das-mirror
spec:
    replicas: 1
    selector:
    matchLabels:
        app: das-mirror
    strategy:
    rollingUpdate:
        maxSurge: 0
        maxUnavailable: 50%
    type: RollingUpdate
    template:
    metadata:
        labels:
        app: das-mirror
    spec:
        containers:
        - command:
        - bash
        - -c
        - |
            mkdir -p /home/user/data/badgerdb
            mkdir -p /home/user/data/syncState
            /usr/local/bin/daserver --data-availability.parent-chain-node-url "<YOUR PARENT CHAIN RPC ENDPOINT>" --data-availability.sequencer-inbox-address "<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>" --enable-rest --rest-addr '0.0.0.0' --log-level 3 --data-availability.local-cache.enable --data-availability.rest-aggregator.enable --data-availability.rest-aggregator.urls "http://your-committee-member.svc.cluster.local:9877" --data-availability.rest-aggregator.online-url-list "<URL TO LIST OF REST ENDPOINTS>" --data-availability.rest-aggregator.sync-to-storage.eager  --data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block "BLOCK NUMBER" --data-availability.rest-aggregator.sync-to-storage.state-dir /home/user/data/syncState --data-availability.s3-storage.enable --data-availability.s3-storage.access-key "<YOUR ACCESS KEY>" --data-availability.s3-storage.bucket "<YOUR BUCKET>" --data-availability.s3-storage.region "<YOUR REGION>" --data-availability.s3-storage.secret-key "<YOUR SECRET KEY>" --data-availability.s3-storage.object-prefix "<YOUR OBJECT KEY PREFIX>/" --data-availability.local-db-storage.enable --data-availability.local-db-storage.data-dir /home/user/data/badgerdb
        image: @latestNitroNodeImage@
        imagePullPolicy: Always
        resources:
            limits:
            cpu: "4"
            memory: 10Gi
            requests:
            cpu: "4"
            memory: 10Gi
        ports:
        - containerPort: 9877
            hostPort: 9877
            protocol: TCP
        volumeMounts:
        - mountPath: /home/user/data/
            name: data
        readinessProbe:
            failureThreshold: 3
            httpGet:
            path: /health/
            port: 9877
            scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
        volumes:
        - name: data
        persistentVolumeClaim:
            claimName: das-mirror
```

## Archive DA servers (for mirror DAS)

Archive DA servers are mirror servers that don't discard any data after expiring. Each DAC should have at the very least one archive DAS to make sure all historical data is available.

To activate the “archive mode” in your DAS, set the parameter `discard-after-timeout` to false in your storage method. For example:

```bash
--data-availability.s3-storage.discard-after-timeout=false
--data-availability.local-db-storage.discard-after-timeout=false
```

Note that local-file-storage and ipfs-storage don't discard data after expiring, so the option `discard-after-timeout` is not available.

Archive servers should make use of the `--data-availability.rest-aggregator.sync-to-storage` options described above to pull in any data that they don't have.

## Testing the DAS

Once the DAS is running, we can test if everything is working correctly using the following methods.

### Test 1: REST health check

The REST interface enabled in the mirror DAS has a health check on the path `/health` which will return 200 if the underlying storage is working, otherwise 503.

Example:

```bash
curl -I <YOUR REST ENDPOINT>
```

## Security considerations

Keep in mind the following information when running the DAS.

For a mirror DAS, using a load balancer is recommended to manage incoming traffic effectively. Additionally, as the REST interface is cacheable, consider deploying a Content Delivery Network (CDN) or caching proxy in front of your REST endpoint. The URL for the REST interface will be publicly known; ensure that it is sufficiently distinct from the RPC endpoint to prevent the latter from being easily discovered.

## What to do next?

Once the DAS is deployed and tested, you'll have to communicate the following information to the chain owner, so they can update the chain parameters and configure the sequencer:

- URL of the REST endpoint

import DASOptionalParameters from './partials/_3-das-optional-parameters.mdx';
import DASMetrics from './partials/_4-das-metrics.mdx';

## Optional parameters

<DASOptionalParameters />

## Metrics

<DASMetrics />
